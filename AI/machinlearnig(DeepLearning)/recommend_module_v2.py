import pandas as pd  # ë°ì´í„° í”„ë ˆì„ ì²˜ë¦¬ìš©
import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚°ìš©
import pickle  # ë°ì´í„° íŒŒì¼ ë¡œë“œìš©
import os
from sklearn.decomposition import TruncatedSVD, NMF  # í–‰ë ¬ë¶„í•´ìš©
from sqlalchemy.dialects.mssql.information_schema import columns
# from db_conn.postgres_db import conn_postgres_db  # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ìš©
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from scipy.sparse import lil_matrix
from tqdm import tqdm
import implicit
from threadpoolctl import threadpool_limits
# from lightfm import LightFM
# from lightfm.data import Dataset
import warnings
warnings.filterwarnings('ignore')

def extract_high_rating_data(minimum_rating=3.5):
    # pickle íŒŒì¼ì—ì„œ í‰ì  ë°ì´í„° ë¡œë“œ
    with open("data/ratings.pkl", "rb") as f:
        df = pickle.load(f)
    userID = "user_id"
    movieID = "movie_id"
    users = df[userID].value_counts().index[:100] # ì˜í™”ë¥¼ ë§ì€ ë³¸ ì‚¬ëŒì˜ ë­í‚¹ 1000ê°œ
    movies = df[movieID].value_counts().index[:]


    data = df[(df[userID].isin(users)) & (df[movieID].isin(movies)) & (df['rating'] >= minimum_rating)]
    data.rename(columns={userID: "user_id", movieID: "movie_id"}, inplace=True)
    return data

def svd_predict_model(users, degree):
    """
    SVD(íŠ¹ì´ê°’ ë¶„í•´)ë¥¼ ì‚¬ìš©í•œ í˜‘ì—… í•„í„°ë§ ì¶”ì²œ ì‹œìŠ¤í…œ

    Args:
      users: ì‚¬ìš©ì-ì˜í™”-í‰ì  ë°ì´í„°í”„ë ˆì„
      degree: SVDì—ì„œ ì‚¬ìš©í•  ì°¨ì› ìˆ˜ (ì ì¬ ìš”ì¸ ê°œìˆ˜)

    Returns:
      ì˜ˆì¸¡ëœ í‰ì ì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„ (user_id, movie_id, predicted_rating)
    """

    # ================================
    # 1ë‹¨ê³„: í”¼ë²— í…Œì´ë¸” ìƒì„±
    # ================================
    # ì‚¬ìš©ìë¥¼ í–‰(index), ì˜í™”ë¥¼ ì—´(columns)ë¡œ í•˜ëŠ” í‰ì  ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
    # fill_value=Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í‰ì ì´ ì—†ëŠ” ê²½ìš° NaNìœ¼ë¡œ ì²˜ë¦¬
    pivot_rating = users.pivot_table(
        index="user_id", columns="movie_id", values="rating", fill_value=None)

    # ================================
    # 2ë‹¨ê³„: ë¹ˆ í‰ì (Nan) ë°ì´í„° ì²˜ë¦¬
    # ================================
    # ê° ì˜í™”ë³„ í‰ê·  í‰ì  ê³„ì‚° (NaN ì œì™¸)
    random_mean = pivot_rating.mean(axis=0)

    # ë¹ˆ í‰ì ì„ í•´ë‹¹ ì˜í™”ì˜ í‰ê·  í‰ì ìœ¼ë¡œ ì±„ìš°ê¸°
    pivot_rating.fillna(random_mean, inplace=True)

    # ================================
    # 3ë‹¨ê³„: SVD í–‰ë ¬ ë¶„í•´ ì¤€ë¹„
    # ================================
    # DataFrameì„ numpy ë°°ì—´ë¡œ ë³€í™˜ (SVD ì•Œê³ ë¦¬ì¦˜ ì…ë ¥ìš©)
    matrix = pivot_rating.values

    # ================================
    # 4ë‹¨ê³„: SVD í–‰ë ¬ ë¶„í•´ ì‹¤í–‰
    # ================================
    # TruncatedSVD: í° í–‰ë ¬ì„ íš¨ìœ¨ì ìœ¼ë¡œ íŠ¹ì´ê°’ ë¶„í•´í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
    # n_components=degree: ì ì¬ ìš”ì¸ì˜ ê°œìˆ˜ (ì°¨ì› ì¶•ì†Œ)
    # random_state=42: ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œê°’
    svd = TruncatedSVD(n_components=degree, random_state=42)

    # fit_transform: ì‚¬ìš©ì ì ì¬ ìš”ì¸ í–‰ë ¬ ìƒì„±
    # ê° ì‚¬ìš©ìë¥¼ 'degree'ê°œì˜ ì ì¬ ìš”ì¸ìœ¼ë¡œ í‘œí˜„
    user_latent_matrix = svd.fit_transform(matrix)

    # components_: ì˜í™” ì ì¬ ìš”ì¸ í–‰ë ¬
    # ê° ì˜í™”ë¥¼ 'degree'ê°œì˜ ì ì¬ ìš”ì¸ìœ¼ë¡œ í‘œí˜„
    item_latent_matrix = svd.components_

    # ================================
    # 5ë‹¨ê³„: ì˜ˆì¸¡ í‰ì  ê³„ì‚°
    # ================================
    # í–‰ë ¬ ê³±ì…ˆìœ¼ë¡œ ëª¨ë“  ì‚¬ìš©ì-ì˜í™” ì¡°í•©ì˜ ì˜ˆì¸¡ í‰ì  ê³„ì‚°
    # user_latent_matrix @ item_latent_matrix = ì˜ˆì¸¡ í‰ì  í–‰ë ¬
    predicted_ratings = user_latent_matrix @ item_latent_matrix

    # ================================
    # 6ë‹¨ê³„: ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    # ================================
    # ì›ë³¸ ë°ì´í„°ì˜ ê³ ìœ í•œ ì‚¬ìš©ì IDì™€ ì˜í™” ID ì¶”ì¶œ
    index = users["user_id"].unique()  # í–‰ ì¸ë±ìŠ¤: ì‚¬ìš©ì ID
    columns = users["movie_id"].unique()  # ì—´ ì¸ë±ìŠ¤: ì˜í™” ID

    # ì˜ˆì¸¡ í‰ì ì„ DataFrameìœ¼ë¡œ ë³€í™˜ (í”¼ë²— í…Œì´ë¸” í˜•íƒœ)
    predicted_rating_df = pd.DataFrame(
        predicted_ratings, index=index, columns=columns)

    # ================================
    # 7ë‹¨ê³„: í”¼ë²— í•´ì œ (Unpivot)
    # ================================
    # stack(): í”¼ë²— í…Œì´ë¸”ì„ ê¸´ í˜•íƒœ(long format)ë¡œ ë³€í™˜
    # reset_index(): MultiIndexë¥¼ ì¼ë°˜ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
    unpivot_predicted_rating_df = predicted_rating_df.stack().reset_index()

    # ì»¬ëŸ¼ëª…ì„ ëª…í™•í•˜ê²Œ ì„¤ì •
    unpivot_predicted_rating_df.columns = ["user_id", "movie_id", "predicted_rating"]

    return unpivot_predicted_rating_df

def performance_metrics(users, model_func, **model_kwargs):
    """
    ì£¼ì–´ì§„ ëª¨ë¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ train/test split í›„ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

    Args:
        users (pd.DataFrame): ì›ë³¸ ì‚¬ìš©ì-ì˜í™”-í‰ì  ë°ì´í„°í”„ë ˆì„
        model_func (callable): ëª¨ë¸ í•¨ìˆ˜ (ì˜ˆ: svd_predict_model, nmf_predict_model ë“±)
        **model_kwargs: ëª¨ë¸ í•¨ìˆ˜ì— ì „ë‹¬í•  íŒŒë¼ë¯¸í„° (ì˜ˆ: degree=50)

    Returns:
        pd.DataFrame: test setì— ëŒ€í•´ ì‹¤ì œ í‰ì ê³¼ ì˜ˆì¸¡ í‰ì ì„ í¬í•¨í•œ DataFrame
    """

    # 1. Train/Test Split
    train_data, test_data = train_test_split(users, test_size=0.2, random_state=42)

    # 2. ëª¨ë¸ ì‹¤í–‰ (train_dataë§Œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ)
    predicted_df = model_func(train_data, **model_kwargs)

    # 3. ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ test ë°ì´í„° ë³‘í•©
    comparison_df = pd.merge(test_data, predicted_df, on=['user_id', 'movie_id'], how='inner')

    # 4. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    actual_ratings = comparison_df['rating']
    predicted_ratings = comparison_df['predicted_rating']

    rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))
    mae = mean_absolute_error(actual_ratings, predicted_ratings)

    print(f"\nğŸ“Š {model_func.__name__} ì„±ëŠ¥ (params={model_kwargs})")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE: {mae:.4f}")

    return comparison_df


def nmf_predict_model(users, degree):
    """
    NMF(ë¹„ìŒìˆ˜ í–‰ë ¬ ë¶„í•´)ë¥¼ ì‚¬ìš©í•œ í˜‘ì—… í•„í„°ë§ ì¶”ì²œ ì‹œìŠ¤í…œ

    Args:
      users: ì‚¬ìš©ì-ì˜í™”-í‰ì  ë°ì´í„°í”„ë ˆì„
      degree: NMFì—ì„œ ì‚¬ìš©í•  ì°¨ì› ìˆ˜ (ì ì¬ ìš”ì¸ ê°œìˆ˜)

    Returns:
      ì˜ˆì¸¡ëœ í‰ì ì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„ (user_id, movie_id, predicted_rating)
    """

    # ================================
    # 1ë‹¨ê³„: í”¼ë²— í…Œì´ë¸” ìƒì„±
    # ================================
    # ì‚¬ìš©ìë¥¼ í–‰(index), ì˜í™”ë¥¼ ì—´(columns)ë¡œ í•˜ëŠ” í‰ì  ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
    # fill_value=Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í‰ì ì´ ì—†ëŠ” ê²½ìš° NaNìœ¼ë¡œ ì²˜ë¦¬
    pivot_rating = users.pivot_table(
        index="user_id", columns="movie_id", values="rating", fill_value=None)

    # ================================
    # 2ë‹¨ê³„: ë¹ˆ í‰ì (NaN) ë°ì´í„° ì²˜ë¦¬
    # ================================
    # ê° ì˜í™”ë³„ í‰ê·  í‰ì  ê³„ì‚° (NaN ì œì™¸)
    random_mean = pivot_rating.mean(axis=0)

    # ë¹ˆ í‰ì ì„ í•´ë‹¹ ì˜í™”ì˜ í‰ê·  í‰ì ìœ¼ë¡œ ì±„ìš°ê¸°
    pivot_rating.fillna(random_mean, inplace=True)

    # ================================
    # 3ë‹¨ê³„: NMF í–‰ë ¬ ë¶„í•´ ì¤€ë¹„
    # ================================
    # DataFrameì„ numpy ë°°ì—´ë¡œ ë³€í™˜ (NMF ì•Œê³ ë¦¬ì¦˜ ì…ë ¥ìš©)
    matrix = pivot_rating.values

    # NMFëŠ” ë¹„ìŒìˆ˜(non-negative) ê°’ë§Œ í—ˆìš©í•˜ë¯€ë¡œ ìŒìˆ˜ê°€ ìˆìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬
    # í‰ì  ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì–‘ìˆ˜ì´ë¯€ë¡œ ëŒ€ë¶€ë¶„ ë¬¸ì œì—†ìŒ
    matrix = np.maximum(matrix, 0)

    # ================================
    # 4ë‹¨ê³„: NMF í–‰ë ¬ ë¶„í•´ ì‹¤í–‰
    # ================================
    # NMF: í–‰ë ¬ì„ ë‘ ê°œì˜ ë¹„ìŒìˆ˜ í–‰ë ¬ì˜ ê³±ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
    # n_components=degree: ì ì¬ ìš”ì¸ì˜ ê°œìˆ˜ (ì°¨ì› ì¶•ì†Œ)
    # init='random': ëœë¤ ì´ˆê¸°í™” ë°©ë²•
    # max_iter=500: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    # tol=1e-5: ìˆ˜ë ´ í—ˆìš© ì˜¤ì°¨
    # random_state=42: ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œê°’
    nmf = NMF(n_components=degree, random_state=42, init='random', max_iter=500, tol=1e-5)

    # fit_transform: ì‚¬ìš©ì ì ì¬ ìš”ì¸ í–‰ë ¬ ìƒì„±
    # ê° ì‚¬ìš©ìë¥¼ 'degree'ê°œì˜ ì ì¬ ìš”ì¸ìœ¼ë¡œ í‘œí˜„
    P = nmf.fit_transform(matrix)

    # components_: ì˜í™” ì ì¬ ìš”ì¸ í–‰ë ¬
    # ê° ì˜í™”ë¥¼ 'degree'ê°œì˜ ì ì¬ ìš”ì¸ìœ¼ë¡œ í‘œí˜„
    Q = nmf.components_

    # ================================
    # 5ë‹¨ê³„: ì˜ˆì¸¡ í‰ì  ê³„ì‚°
    # ================================
    # í–‰ë ¬ ê³±ì…ˆìœ¼ë¡œ ëª¨ë“  ì‚¬ìš©ì-ì˜í™” ì¡°í•©ì˜ ì˜ˆì¸¡ í‰ì  ê³„ì‚°
    predicted_ratings = P @ Q

    # ================================
    # 6ë‹¨ê³„: ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    # ================================
    # ì›ë³¸ ë°ì´í„°ì˜ ê³ ìœ í•œ ì‚¬ìš©ì IDì™€ ì˜í™” ID ì¶”ì¶œ
    index = users["user_id"].unique()  # í–‰ ì¸ë±ìŠ¤: ì‚¬ìš©ì ID
    columns = users["movie_id"].unique()  # ì—´ ì¸ë±ìŠ¤: ì˜í™” ID

    # ì˜ˆì¸¡ í‰ì ì„ DataFrameìœ¼ë¡œ ë³€í™˜ (í”¼ë²— í…Œì´ë¸” í˜•íƒœ)
    predicted_rating_df = pd.DataFrame(
        predicted_ratings, index=index, columns=columns)

    # ================================
    # 7ë‹¨ê³„: í”¼ë²— í•´ì œ (Unpivot)
    # ================================
    # stack(): í”¼ë²— í…Œì´ë¸”ì„ ê¸´ í˜•íƒœ(long format)ë¡œ ë³€í™˜
    # reset_index(): MultiIndexë¥¼ ì¼ë°˜ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
    unpivot_predicted_rating_df = predicted_rating_df.stack().reset_index()

    # ì»¬ëŸ¼ëª…ì„ ëª…í™•í•˜ê²Œ ì„¤ì •
    unpivot_predicted_rating_df.columns = ["user_id", "movie_id", "predicted_rating"]

    return unpivot_predicted_rating_df

def imf_predict_model(users, factors=10, minimum_num_ratings=4, epochs=50):
    """
    IMF(Implicit Matrix Factorization)ë¥¼ ì‚¬ìš©í•œ í˜‘ì—… í•„í„°ë§ ì¶”ì²œ ì‹œìŠ¤í…œ

    Args:
      users: ì‚¬ìš©ì-ì˜í™”-í‰ì  ë°ì´í„°í”„ë ˆì„
      factors: ALSì—ì„œ ì‚¬ìš©í•  ì ì¬ ìš”ì¸ ìˆ˜
      minimum_num_ratings: ìµœì†Œ í‰ì  ê°œìˆ˜ (ì´ë³´ë‹¤ ì ì€ ìƒí˜¸ì‘ìš©ì„ ê°€ì§„ ì‚¬ìš©ì/ì˜í™” ì œì™¸)
      epochs: í•™ìŠµ ë°˜ë³µ íšŸìˆ˜

    Returns:
      ê° ì‚¬ìš©ìë³„ ìƒìœ„ Nê°œ ì¶”ì²œ ì˜í™” ë¦¬ìŠ¤íŠ¸
    """

    # ================================
    # 1ë‹¨ê³„: ë°ì´í„° í•„í„°ë§
    # ================================
    # ìµœì†Œ í‰ì  ê°œìˆ˜ ì´ìƒì˜ ìƒí˜¸ì‘ìš©ì„ ê°€ì§„ ì‚¬ìš©ìë§Œ ì„ íƒ


    user_counts = users["user_id"].value_counts()
    valid_users = user_counts[user_counts >= minimum_num_ratings].index

    # ìµœì†Œ í‰ì  ê°œìˆ˜ ì´ìƒì˜ ìƒí˜¸ì‘ìš©ì„ ê°€ì§„ ì˜í™”ë§Œ ì„ íƒ
    movie_counts = users["movie_id"].value_counts()
    valid_movies = movie_counts[movie_counts >= minimum_num_ratings].index

    # í•„í„°ë§ëœ ë°ì´í„°ë§Œ ì‚¬ìš©
    filtered_users = users[
        (users["user_id"].isin(valid_users)) & (users["movie_id"].isin(valid_movies))]

    # ================================
    # 2ë‹¨ê³„: ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„±
    # ================================
    # í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„±
    num_users = filtered_users["user_id"].nunique()
    num_movies = filtered_users["movie_id"].nunique()

    user_id2index = {
        user_id: i for i, user_id in enumerate(filtered_users["user_id"].unique())}
    movie_id2index = {
        movie_id: i for i, movie_id in enumerate(filtered_users["movie_id"].unique())}

    # ================================
    # 3ë‹¨ê³„: í¬ì†Œ í–‰ë ¬ ìƒì„±
    # ================================
    # ì‚¬ìš©ì-ì˜í™” ìƒí˜¸ì‘ìš© í–‰ë ¬ ìƒì„±
    matrix = lil_matrix((num_users, num_movies))

    # ëª¨ë“  í‰ì ì„ 1.0ìœ¼ë¡œ ë³€í™˜ (ìƒí˜¸ì‘ìš© ì—¬ë¶€ë§Œ ê³ ë ¤)
    for _, row in tqdm(filtered_users.iterrows(), total=len(filtered_users)):
        user_idx = user_id2index[row["user_id"]]
        movie_idx = movie_id2index[row["movie_id"]]
        matrix[user_idx, movie_idx] = 1.0

    # ================================
    # 4ë‹¨ê³„: CSR í˜•íƒœë¡œ ë³€í™˜
    # ================================
    # í¬ì†Œ í–‰ë ¬ì„ CSR(Compressed Sparse Row) í˜•íƒœë¡œ ë³€í™˜ (ì—°ì‚° íš¨ìœ¨ì„±)
    matrix_csr = matrix.tocsr()

    # ================================
    # 5ë‹¨ê³„: ALS ëª¨ë¸ í•™ìŠµ
    # ================================
    # AlternatingLeastSquares: implicit feedbackì„ ìœ„í•œ í–‰ë ¬ë¶„í•´ ì•Œê³ ë¦¬ì¦˜
    # factors: ì ì¬ ìš”ì¸ì˜ ê°œìˆ˜ (ì°¨ì› ì¶•ì†Œ)
    # iterations: í•™ìŠµ ë°˜ë³µ íšŸìˆ˜
    # calculate_training_loss: í•™ìŠµ ì†ì‹¤ ê³„ì‚° ì—¬ë¶€
    # random_state: ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œê°’
    model = implicit.als.AlternatingLeastSquares(
        factors=factors,
        iterations=epochs,
        calculate_training_loss=True,
        random_state=42
    )

    # ================================
    # 6ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
    # ================================
    # threadpool_limits: BLAS ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ (ë©”ëª¨ë¦¬ ì•ˆì •ì„±)
    with threadpool_limits(limits=4, user_api="blas"):
        model.fit(matrix_csr)

    # ================================
    # 7ë‹¨ê³„: ì¶”ì²œ ê²°ê³¼ ìƒì„±
    # ================================
    # ê° ì‚¬ìš©ìë³„ ìƒìœ„ Nê°œ ì˜í™” ì¶”ì²œ
    predicted_model = model.recommend_all(matrix_csr, N=10)

    # ================================
    # 8ë‹¨ê³„: DataFrame í˜•íƒœë¡œ ë³€í™˜
    # ================================
    # ì¶”ì²œ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    recommendations = []

    # ì¸ë±ìŠ¤ë¥¼ ì›ë³¸ IDë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ì—­ë§¤í•‘ ìƒì„±
    index2user_id = {v: k for k, v in user_id2index.items()}
    index2movie_id = {v: k for k, v in movie_id2index.items()}

    # recommend_all ê²°ê³¼ë¥¼ ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ë³€í™˜
    for user_idx in range(len(predicted_model)):
        original_user_id = index2user_id[user_idx]
        user_recommendations = predicted_model[user_idx]

        # ê° ì‚¬ìš©ìì˜ ì¶”ì²œ ì˜í™”ë“¤ì„ ì²˜ë¦¬
        for rank, movie_idx in enumerate(user_recommendations):
            original_movie_id = index2movie_id[movie_idx]

            # ì¶”ì²œ ì ìˆ˜ëŠ” ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚° í›„ 0~5ì  ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
            # 1ìœ„ê°€ 5ì , ë§ˆì§€ë§‰ ìˆœìœ„ê°€ 0ì ì— ê°€ê¹ê²Œ ì„¤ì •
            normalized_score = 1.0 - (rank / len(user_recommendations))  # 0~1 ë²”ìœ„
            predicted_score = normalized_score * 5.0  # 0~5ì  ë²”ìœ„ë¡œ ë³€í™˜

            recommendations.append({
                'user_id': original_user_id,
                'movie_id': original_movie_id,
                'predicted_rating': float(predicted_score)
            })
    print(recommendations)

    # DataFrameìœ¼ë¡œ ë³€í™˜
    predicted_df = pd.DataFrame(recommendations)

    return predicted_df

def bpr_predict_model(users, factors=10, minimum_num_ratings=4, epochs=50):
    """
    IMF(Implicit Matrix Factorization)ë¥¼ ì‚¬ìš©í•œ í˜‘ì—… í•„í„°ë§ ì¶”ì²œ ì‹œìŠ¤í…œ

    Args:
      users: ì‚¬ìš©ì-ì˜í™”-í‰ì  ë°ì´í„°í”„ë ˆì„
      factors: ALSì—ì„œ ì‚¬ìš©í•  ì ì¬ ìš”ì¸ ìˆ˜
      minimum_num_ratings: ìµœì†Œ í‰ì  ê°œìˆ˜ (ì´ë³´ë‹¤ ì ì€ ìƒí˜¸ì‘ìš©ì„ ê°€ì§„ ì‚¬ìš©ì/ì˜í™” ì œì™¸)
      epochs: í•™ìŠµ ë°˜ë³µ íšŸìˆ˜

    Returns:
      ê° ì‚¬ìš©ìë³„ ìƒìœ„ Nê°œ ì¶”ì²œ ì˜í™” ë¦¬ìŠ¤íŠ¸
    """

    # ================================
    # 1ë‹¨ê³„: ë°ì´í„° í•„í„°ë§
    # ================================
    # ìµœì†Œ í‰ì  ê°œìˆ˜ ì´ìƒì˜ ìƒí˜¸ì‘ìš©ì„ ê°€ì§„ ì‚¬ìš©ìë§Œ ì„ íƒ
    user_counts = users["user_id"].value_counts()
    valid_users = user_counts[user_counts >= minimum_num_ratings].index

    # ìµœì†Œ í‰ì  ê°œìˆ˜ ì´ìƒì˜ ìƒí˜¸ì‘ìš©ì„ ê°€ì§„ ì˜í™”ë§Œ ì„ íƒ
    movie_counts = users["movie_id"].value_counts()
    valid_movies = movie_counts[movie_counts >= minimum_num_ratings].index

    # í•„í„°ë§ëœ ë°ì´í„°ë§Œ ì‚¬ìš©
    filtered_users = users[
        (users["user_id"].isin(valid_users)) & (users["movie_id"].isin(valid_movies))]

    # ================================
    # 2ë‹¨ê³„: ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„±
    # ================================
    # í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„±
    num_users = filtered_users["user_id"].nunique()
    num_movies = filtered_users["movie_id"].nunique()

    user_id2index = {
        user_id: i for i, user_id in enumerate(filtered_users["user_id"].unique())}
    movie_id2index = {
        movie_id: i for i, movie_id in enumerate(filtered_users["movie_id"].unique())}

    # ================================
    # 3ë‹¨ê³„: í¬ì†Œ í–‰ë ¬ ìƒì„±
    # ================================
    # ì‚¬ìš©ì-ì˜í™” ìƒí˜¸ì‘ìš© í–‰ë ¬ ìƒì„±
    matrix = lil_matrix((num_users, num_movies))

    # ëª¨ë“  í‰ì ì„ 1.0ìœ¼ë¡œ ë³€í™˜ (ìƒí˜¸ì‘ìš© ì—¬ë¶€ë§Œ ê³ ë ¤)
    for _, row in tqdm(filtered_users.iterrows(), total=len(filtered_users)):
        user_idx = user_id2index[row["user_id"]]
        movie_idx = movie_id2index[row["movie_id"]]
        matrix[user_idx, movie_idx] = 1.0

    # ================================
    # 4ë‹¨ê³„: CSR í˜•íƒœë¡œ ë³€í™˜
    # ================================
    # í¬ì†Œ í–‰ë ¬ì„ CSR(Compressed Sparse Row) í˜•íƒœë¡œ ë³€í™˜ (ì—°ì‚° íš¨ìœ¨ì„±)
    matrix_csr = matrix.tocsr()

    # ================================
    # 5ë‹¨ê³„: ALS ëª¨ë¸ í•™ìŠµ
    # ================================
    # AlternatingLeastSquares: implicit feedbackì„ ìœ„í•œ í–‰ë ¬ë¶„í•´ ì•Œê³ ë¦¬ì¦˜
    # factors: ì ì¬ ìš”ì¸ì˜ ê°œìˆ˜ (ì°¨ì› ì¶•ì†Œ)
    # iterations: í•™ìŠµ ë°˜ë³µ íšŸìˆ˜
    # calculate_training_loss: í•™ìŠµ ì†ì‹¤ ê³„ì‚° ì—¬ë¶€
    # random_state: ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œê°’
    model = implicit.bpr.BayesianPersonalizedRanking(
        factors=factors,
        learning_rate=0.01,
        regularization=0.01,
        iterations=100,
        random_state=42
    )

    # ================================
    # 6ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
    # ================================
    # threadpool_limits: BLAS ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ (ë©”ëª¨ë¦¬ ì•ˆì •ì„±)
    with threadpool_limits(limits=4, user_api="blas"):
        model.fit(matrix_csr)

    # ================================
    # 7ë‹¨ê³„: ì¶”ì²œ ê²°ê³¼ ìƒì„±
    # ================================
    # ê° ì‚¬ìš©ìë³„ ìƒìœ„ Nê°œ ì˜í™” ì¶”ì²œ
    predicted_model = model.recommend_all(matrix_csr, N=10)

    # ================================
    # 8ë‹¨ê³„: DataFrame í˜•íƒœë¡œ ë³€í™˜
    # ================================
    # ì¶”ì²œ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    recommendations = []

    # ì¸ë±ìŠ¤ë¥¼ ì›ë³¸ IDë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ì—­ë§¤í•‘ ìƒì„±
    index2user_id = {v: k for k, v in user_id2index.items()}
    index2movie_id = {v: k for k, v in movie_id2index.items()}

    # recommend_all ê²°ê³¼ë¥¼ ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ë³€í™˜
    for user_idx in range(len(predicted_model)):
        original_user_id = index2user_id[user_idx]
        user_recommendations = predicted_model[user_idx]

        # ê° ì‚¬ìš©ìì˜ ì¶”ì²œ ì˜í™”ë“¤ì„ ì²˜ë¦¬
        for rank, movie_idx in enumerate(user_recommendations):
            original_movie_id = index2movie_id[movie_idx]

            # ì¶”ì²œ ì ìˆ˜ëŠ” ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚° í›„ 0~5ì  ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
            # 1ìœ„ê°€ 5ì , ë§ˆì§€ë§‰ ìˆœìœ„ê°€ 0ì ì— ê°€ê¹ê²Œ ì„¤ì •
            normalized_score = 1.0 - (rank / len(user_recommendations))  # 0~1 ë²”ìœ„
            predicted_score = normalized_score * 5.0  # 0~5ì  ë²”ìœ„ë¡œ ë³€í™˜

            recommendations.append({
                'user_id': original_user_id,
                'movie_id': original_movie_id,
                'predicted_rating': float(predicted_score)
            })
    print(recommendations)

    # DataFrameìœ¼ë¡œ ë³€í™˜
    predicted_df = pd.DataFrame(recommendations)

    return predicted_df

# def lightfm_bpr_predict_model(users, factors=2, minimum_num_ratings=4, epochs=50):
#     """
#     LightFMê³¼ BPR Lossë¥¼ ì‚¬ìš©í•œ í˜‘ì—… í•„í„°ë§ ì¶”ì²œ ì‹œìŠ¤í…œ
#
#     Args:
#       users (pd.DataFrame): ì‚¬ìš©ì-ì˜í™”-í‰ì  ë°ì´í„°í”„ë ˆì„
#       factors (int): ì ì¬ ìš”ì¸(Latent Factor)ì˜ ìˆ˜
#       minimum_num_ratings (int): í•„í„°ë§ì„ ìœ„í•œ ìµœì†Œ í‰ì  ê°œìˆ˜
#       epochs (int): í•™ìŠµ ë°˜ë³µ íšŸìˆ˜
#
#     Returns:
#       pd.DataFrame: ê° ì‚¬ìš©ì-ì˜í™” ìŒì— ëŒ€í•œ ì˜ˆì¸¡ ì ìˆ˜ ë°ì´í„°í”„ë ˆì„
#     """
#
#     # ================================
#     # 1ë‹¨ê³„: ë°ì´í„° í•„í„°ë§ (ì›ë³¸ ì½”ë“œì™€ ë™ì¼)
#     # ================================
#     user_counts = users["user_id"].value_counts()
#     valid_users = user_counts[user_counts >= minimum_num_ratings].index
#
#     movie_counts = users["movie_id"].value_counts()
#     valid_movies = movie_counts[movie_counts >= minimum_num_ratings].index
#
#     filtered_data = users[
#         (users["user_id"].isin(valid_users)) & (users["movie_id"].isin(valid_movies))
#         ].copy()
#
#
#     # print(filtered_data)
#     # exit()
#
#     # í•„í„°ë§ëœ ë°ì´í„°ì˜ ê³ ìœ  ì‚¬ìš©ì ë° ì˜í™” ëª©ë¡
#     unique_user_ids = sorted(filtered_data['user_id'].unique())
#     unique_movie_ids = sorted(filtered_data['movie_id'].unique())
#
#     # ================================
#     # 2ë‹¨ê³„: LightFM Dataset ìƒì„± ë° ë§¤í•‘
#     # ================================
#     # Dataset ê°ì²´ë¥¼ ìƒì„±í•˜ê³  ì‚¬ìš©ì/ì•„ì´í…œ IDë¥¼ ë‚´ë¶€ ì¸ë±ìŠ¤ì— ë§¤í•‘í•©ë‹ˆë‹¤.
#     dataset = Dataset()
#     dataset.fit(users=unique_user_ids, items=unique_movie_ids)
#
#     # ìƒí˜¸ì‘ìš© í–‰ë ¬ì„ êµ¬ì¶•í•©ë‹ˆë‹¤. BPRì€ ìƒí˜¸ì‘ìš© ìœ ë¬´ê°€ ì¤‘ìš”í•˜ë¯€ë¡œ ê°€ì¤‘ì¹˜ëŠ” 1ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
#     (interactions, weights) = dataset.build_interactions(
#         (row['user_id'], row['movie_id'])
#         for index, row in filtered_data.iterrows()
#     )
#     # print(interactions)
#     # exit()
#     # ================================
#     # 3ë‹¨ê³„: BPR ëª¨ë¸ í•™ìŠµ
#     # ================================
#     # loss='bpr': Bayesian Personalized Ranking ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
#     model = LightFM(
#         no_components=factors,
#         loss='bpr',
#         learning_rate=0.01,
#         random_state=42
#     )
#
#     # ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
#     model.fit(
#         interactions,
#         epochs=epochs,
#         num_threads=os.cpu_count()  # ì‚¬ìš© ê°€ëŠ¥í•œ CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì ˆ
#     )
#
#
#     # ================================
#     # 4ë‹¨ê³„: ëª¨ë“  ì‚¬ìš©ì-ì˜í™” ìŒì— ëŒ€í•œ ì˜ˆì¸¡ ì ìˆ˜ ìƒì„± (íš¨ìœ¨ì„± ê°œì„ )
#     # ================================
#     # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  DataFrame ë¦¬ìŠ¤íŠ¸
#     predictions_list = []
#
#     # Datasetì—ì„œ ìƒì„±ëœ ë‚´ë¶€ ë§¤í•‘ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     user_id_map, _, _, _ = dataset.mapping()
#
#     # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© í‘œì‹œ
#     for user_id in tqdm(unique_user_ids, desc="Predicting scores"):
#         # LightFM ëª¨ë¸ì€ ë‚´ë¶€ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
#         user_idx = user_id_map[user_id]
#
#         # í•´ë‹¹ ì‚¬ìš©ìì— ëŒ€í•´ ëª¨ë“  ì˜í™”ì˜ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
#         item_indices = np.arange(len(unique_movie_ids))
#         scores = model.predict(user_idx, item_indices)
#
#         # [ìˆ˜ì •ëœ ë¶€ë¶„]
#         # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë§¤ë²ˆ appendí•˜ëŠ” ëŒ€ì‹ , ì‚¬ìš©ìë³„ë¡œ DataFrameì„ ë§Œë“¤ì–´ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤.
#         # ì´ ë°©ì‹ì´ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤.
#         df_temp = pd.DataFrame({
#             'user_id': user_id,
#             'movie_id': unique_movie_ids,
#             'score': scores
#         })
#         predictions_list.append(df_temp)
#
#     # [ìˆ˜ì •ëœ ë¶€ë¶„]
#     # ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ëœ ëª¨ë“  DataFrameì„ í•œ ë²ˆì— íš¨ìœ¨ì ìœ¼ë¡œ ê²°í•©í•©ë‹ˆë‹¤.
#     predicted_df = pd.concat(predictions_list, ignore_index=True)
#
#     return predicted_df

if __name__ == "__main__":
    users = extract_high_rating_data()

    # âœ… SVD í‰ê°€
    svd_results = performance_metrics(users, svd_predict_model, degree=50)
    print(svd_results.head())

    # âœ… NMF í‰ê°€
    nmf_results = performance_metrics(users, nmf_predict_model, degree=20)
    print(nmf_results.head())

    # âœ… IMF (ALS) í‰ê°€
    imf_results = performance_metrics(users, imf_predict_model, factors=20, epochs=30)
    print(imf_results.head())

    # âœ… BPR í‰ê°€
    bpr_results = performance_metrics(users, bpr_predict_model, factors=20, epochs=30)
    print(bpr_results.head())

    exit()
    # print(users.shape)
    # exit()
    # degree=10: 10ê°œì˜ ì ì¬ ìš”ì¸ìœ¼ë¡œ ì°¨ì› ì¶•ì†Œ
    # ê²°ê³¼: ëª¨ë“  ì‚¬ìš©ì-ì˜í™” ì¡°í•©ì˜ ì˜ˆì¸¡ í‰ì 
    # users_df = svd_predict_model(users, 10)
    # conn_postgres_db(users_df, "kogo", "1111", "mydb", "svd_model")
    # print("svd success")
    # users_df = nmf_predict_model(users, 10)
    # conn_postgres_db(users_df, "kogo", "1111", "mydb", "nmf_model")
    # print("nmf success")
    # users_df = imf_predict_model(users)
    # conn_postgres_db(users_df, "kogo", "1111", "mydb", "imf_model")
    # print("imf success")
    # users_df = bpr_predict_model(users)
    # conn_postgres_db(users_df, "kogo", "1111", "mydb", "bpr_model")
    # print("bpr success")
    # users_df = lightfm_bpr_predict_model(users)
    # print(users_df)

    # print(users_df[users_df["user_id"]==143])

    # ì „ì²´ DataFrame ì¶œë ¥ ì„¤ì •
    # pd.set_option('display.max_rows', None)  # ëª¨ë“  í–‰ ì¶œë ¥
    # pd.set_option('display.max_columns', None)  # ëª¨ë“  ì—´ ì¶œë ¥
    # pd.set_option('display.width', None)  # ë„ˆë¹„ ì œí•œ ì—†ìŒ
    # pd.set_option('display.max_colwidth', None)  # ì—´ ë„ˆë¹„ ì œí•œ ì—†ìŒ
    #
    # print(users_df)

    # ================================
    # 5ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    # ================================
    # conn_postgres_db(users_df, "kogo", "1111", "mydb", "nmf_model")